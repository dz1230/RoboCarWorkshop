{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set-up of an AI-controlled self-driving Robo-Car\n",
    "\n",
    "In this notebook, we will focus on detecting whether an image contains a stop sign. This is a binary classification task in the field of computer vision. Using TensorFlow, we will demonstrate how to implement and train a neural network to perform this classification task.\n",
    "\n",
    "TensorFlow is an open-source framework for numerical computation and machine learning. We will cover the essential theoretical foundations of neural network-based classification and utilize TensorFlow to develop our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries (This may take a while)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models, layers, regularizers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data\n",
    "\n",
    "The datasets are provided separately. Later, you can use your own data and compare models trained with different data.\n",
    "To work with our model, the images have to be 224x224 pixels in size.\n",
    "\n",
    "The directory structure of every dataset should be as follows:\n",
    "\n",
    "```\n",
    "/path/to/dataset/\n",
    "└───stop_signs/\n",
    "│   │   image_with_stop_sign_1.jpg\n",
    "│   │   ...\n",
    "│   │   image_with_stop_sign_N.jpg\n",
    "└───no_stop_signs/\n",
    "    │   image_without_stop_sign_1.jpg\n",
    "    │   ...\n",
    "    │   image_without_stop_sign_N.jpg\n",
    "```\n",
    "\n",
    "We need both a training and a test dataset.\n",
    "\n",
    "Tasks to accomplish:\n",
    "\n",
    "- Load the training and test datasets from their respective directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: Replace the paths with the path to your training and test data\n",
    "train_dir = Path(\"data/train/\")\n",
    "test_dir = Path(\"data/test/\")\n",
    "# END TASK\n",
    "\n",
    "# Counts the number of images\n",
    "train_image_count = len(list(train_dir.glob('*/*.jpg')))\n",
    "test_image_count = len(list(test_dir.glob('*/*.jpg')))\n",
    "print(\"Train image count: \", train_image_count)\n",
    "print(\"Test image count: \", test_image_count)\n",
    "\n",
    "img_height = 224 \n",
    "img_width = 224\n",
    "\n",
    "dropout_rate = 0.3\n",
    "dense_layer_size = 64\n",
    "batch_size = 16\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        test_dir,\n",
    "        image_size=(img_height, img_width),\n",
    "        batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "\n",
    "To improve the variation of our training data, we can augment some images to have a different brightness or shift their pixels. If we do that, we have to make sure not to introduce unwanted side effects.\n",
    "\n",
    "Tasks to accomplish:\n",
    "\n",
    "- (Optional) Augment the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation_probability = 0.5 # set to 0.0 to disable augmentation\n",
    "brightness_vs_padding_probability = 0.7\n",
    "\n",
    "def random_brightness(images, labels):\n",
    "    \"\"\"\n",
    "    Apply random brightness to a batch of images.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    images: tf.Tensor\n",
    "        A batch of images.\n",
    "    labels: tf.Tensor\n",
    "        A batch of labels.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    images_brightness: tf.Tensor\n",
    "        A batch of images with random brightness.\n",
    "    labels: tf.Tensor\n",
    "        A batch of labels.\n",
    "    \"\"\"\n",
    "    # TASK: Your code here\n",
    "    # generate randomness\n",
    "    seed = (tf.random.uniform([], 0, 10000, dtype=tf.int32), tf.random.uniform([], 0, 10000, dtype=tf.int32))\n",
    "    # convert to float for brightness augmentation\n",
    "    images_float = tf.cast(images, tf.float32) / 255.0\n",
    "    images_brightness = tf.image.stateless_random_brightness(images_float, max_delta=0.4, seed=seed)\n",
    "    # prevent black images (stop signs need to be recognizable)\n",
    "    images_brightness = tf.clip_by_value(images_brightness, 0.2, 1.0)\n",
    "    # convert back to uint8 for MobileNetV3\n",
    "    images_brightness = tf.cast(images_brightness * 255.0, tf.uint8)\n",
    "    return images_brightness, labels\n",
    "    # END TASK\n",
    "\n",
    "def random_shift_and_pad(images, labels):\n",
    "    \"\"\"\n",
    "    Apply random shift and padding to a batch of images.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    images: tf.Tensor\n",
    "        A batch of images.\n",
    "    labels: tf.Tensor\n",
    "        A batch of labels.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    padded_images: tf.Tensor\n",
    "        A batch of images with random shift and padding.\n",
    "    labels: tf.Tensor\n",
    "        A batch of labels.\n",
    "    \"\"\"\n",
    "    # TASK: Your code here\n",
    "    # generate randomness\n",
    "    shift_amount_x = tf.random.uniform([], -15, 15, dtype=tf.int32)\n",
    "    shift_amount_y = tf.random.uniform([], -25, 25, dtype=tf.int32)\n",
    "    pad_amount_x_before = tf.maximum(0, shift_amount_x)\n",
    "    pad_amount_x_after = tf.maximum(0, -shift_amount_x)\n",
    "    pad_amount_y_before = tf.maximum(0, shift_amount_y)\n",
    "    pad_amount_y_after = tf.maximum(0, -shift_amount_y)\n",
    "    # shift images\n",
    "    images_roll = tf.roll(images, shift_amount_x, axis=2)\n",
    "    images_roll = tf.roll(images_roll, shift_amount_y, axis=1)\n",
    "    # crop parts that will be padded\n",
    "    resized_images = tf.image.crop_to_bounding_box(\n",
    "        images_roll, \n",
    "        tf.maximum(0, shift_amount_y), \n",
    "        tf.maximum(0, shift_amount_x), \n",
    "        img_height - tf.abs(shift_amount_y), \n",
    "        img_width - tf.abs(shift_amount_x)\n",
    "    )\n",
    "    # pad cropped parts, restores original image size\n",
    "    padded_images = tf.pad(resized_images, \n",
    "        [[0, 0], [pad_amount_y_before, pad_amount_y_after], [pad_amount_x_before, pad_amount_x_after], [0, 0]],\n",
    "        mode='CONSTANT', \n",
    "        constant_values=128\n",
    "    )\n",
    "    return padded_images, labels\n",
    "    # END TASK\n",
    "\n",
    "def augment(images, labels):\n",
    "    \"\"\"\n",
    "    Apply random augmentation to a batch of images.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    images: tf.Tensor\n",
    "        A batch of images.\n",
    "    labels: tf.Tensor\n",
    "        A batch of labels.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    augmented_images: tf.Tensor\n",
    "        A batch of images with random augmentation.\n",
    "    labels: tf.Tensor\n",
    "        A batch of labels.\n",
    "    \"\"\"\n",
    "    images = tf.cast(images, tf.uint8)\n",
    "\n",
    "    if tf.random.uniform([]) > augmentation_probability:\n",
    "        return images, labels\n",
    "    if tf.random.uniform([]) < brightness_vs_padding_probability:\n",
    "        return random_brightness(images, labels)\n",
    "    else:\n",
    "        return random_shift_and_pad(images, labels)\n",
    "    \n",
    "train_ds = train_ds.map(augment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the first 9 training images\n",
    "\n",
    "example_images, _ = next(iter(train_ds))\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(min(9, train_image_count)):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(example_images[i].numpy().astype(\"uint8\"))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the first 9 test images\n",
    "\n",
    "example_images, _ = next(iter(test_ds))\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(min(9, train_image_count)):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(example_images[i].numpy().astype(\"uint8\"))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model\n",
    "\n",
    "In this section, we delve into the construction of a neural network using the MobileNetV3 model, an architecture renowned for its efficiency on mobile and embedded vision applications. This part of the workshop will cover the integration and customization of MobileNetV3 for binary classification tasks.\n",
    "\n",
    "We will load the MobileNetV3Small model with pre-trained ImageNet weights and freeze its base layers to leverage the learned features. The model is augmented with a few additional layers, including a dense layer, dropout, batch normalization, and a final output layer to perform binary classification.\n",
    "\n",
    "Below is the code to load the MobileNetV3 model, selectively unfreeze a couple of its top layers, and build a sequential model using TensorFlow's Keras API. The model is then compiled and summarized to provide an overview of its architecture.\n",
    "\n",
    "Tasks to accomplish:\n",
    "\n",
    "- Add your own classification head to the MobileNetV3Small base model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MobileNetV3 model\n",
    "base_model = keras.applications.MobileNetV3Small(\n",
    "    input_shape=None,\n",
    "    alpha=1.0,\n",
    "    minimalistic=False,\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    classes=None,\n",
    "    pooling=\"avg\",\n",
    "    dropout_rate=dropout_rate,\n",
    "    classifier_activation=None,\n",
    "    include_preprocessing=True,\n",
    ")\n",
    "\n",
    "# Freeze the base model\n",
    "trainable_layers = 2\n",
    "base_model.trainable = False\n",
    "for layer in base_model.layers[-trainable_layers:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Add a classification head\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    # TASK: Your code here\n",
    "    layers.Dense(dense_layer_size, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "    layers.Dropout(dropout_rate),\n",
    "    layers.BatchNormalization(),\n",
    "    # END TASK\n",
    "    layers.Dense(1, activation='sigmoid') \n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=[keras.metrics.BinaryAccuracy(name='accuracy')])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "\n",
    "To optimize the training process, we utilize Early Stopping and TensorBoard callbacks. Early Stopping monitors the validation loss and halts training if it doesn't improve for three consecutive epochs, restoring the best weights observed. TensorBoard logs training metrics, allowing detailed visualization and analysis. It is not required to use TensorBoard, but it can be useful if you want to improve the model. The model is trained with these callbacks to enhance performance and monitor progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# early stopping\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',   # Beobachtete Metrik ist der Validierungsverlust\n",
    "    patience=3,           # Anzahl der Epochen ohne Verbesserung bevor das Training gestoppt wird\n",
    "    verbose=1,            # Zeigt eine Nachricht an, wenn das Training gestoppt wird\n",
    "    restore_best_weights=True # Stellt die Gewichte der besten Epoche wieder her\n",
    ")\n",
    "\n",
    "# Tensorboard\n",
    "log_dir = \"logs/fit/\" + \"mobileNet_\" + \"Dataset_\" + train_dir.name + \"_Batch_size_\" + str(batch_size) + \"_dropout_rate_\" + str(dropout_rate) + \"_dense_layer_size_\" + str(dense_layer_size) + \"_\" + str(datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_ds, epochs=25, \n",
    "    validation_data=test_ds, \n",
    "    callbacks=[early_stopping_callback, tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save(\"stop_sign_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uploading to Raspberry Pi\n",
    "\n",
    "We can upload the model to the Raspberry Pi using ssh. The first step is to connect the Raspberry Pi to the same network as us.\n",
    "\n",
    "The easiest way to do this is to create a new OS image using the Raspberry Pi Imager tool. When creating the image, enable the SSH service and set the WiFi connection to a WiFi HotSpot of your Smartphone. Save the image onto the microSD card in the Raspberry Pi (you need an SD-Card reader for this). Enable your Smartphones WiFi Hotspot. Insert the microSD card back into the Raspberry Pi and power it. The Raspberry Pi is connected once you see it in your Smartphones HotSpot settings under \"Connected devices\" (The exact setting may vary depending on phone and operating system). There you should also find the IP address of the Raspberry Pi.\n",
    "\n",
    "Connect your computer to the same WiFi HotSpot. Open VSCode and install the [Remote - SSH](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-ssh) extension. Use Ctrl+Shift+P to open the VSCode command prompt and select \"Remote-SSH: Connect to Host...\". Select \"Add new Host\" and type: ```ssh pi@<IP>```, where \"\\<IP\\>\" is the IP address of the Raspberry Pi. If VSCode asks for an operating system, select Linux. A new, remote VSCode window should now open, where you have access to the file system of the Raspberry Pi. Copy the model (stop_sign_model.h5) and the \"roboCar.py\" python script and paste it there.\n",
    "\n",
    "## Test the Model on the RoboCar\n",
    "\n",
    "Open a Terminal in the Remote VSCode window. Run the following commands to install the required libraries:\n",
    "\n",
    "```bash\n",
    "# TODO how did we install tensorflow, cv2, numpy?\n",
    "```\n",
    "\n",
    "Run ```python3 roboCar.py``` on the Raspberry Pi to start the car. Warning: It will start driving. Place a stop sign in front of its camera to see if the model works.\n",
    "\n",
    "Important: Only stop the script (with Ctrl+C) if the car is already stopped! Otherwise it might not stop."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RoboCarWorkshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
